{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "img_trans = A.Compose([\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(0, 0.2), contrast_limit=(0, 0.5), p=0.8),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "            A.Sharpen(alpha=(0.2, 0.5), lightness=(0.2, 0.5), always_apply=False, p=1.0),\n",
    "            A.ColorJitter(brightness = 0.2, saturation = 0.5, hue = 0.5),\n",
    "            A.VerticalFlip(),\n",
    "            A.HorizontalFlip(),\n",
    "            ])\n",
    "            \n",
    "img_trans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05112022164747\n",
      "05-11-22,16:47:47\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.now().strftime(\"%d%m%Y%H%M%S\")\n",
    "print(date)\n",
    "datef = datetime.now().strftime(\"%d-%m-%y,%H:%M:%S\")\n",
    "print(datef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3]\n",
    "import numpy as np\n",
    "print(np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000])\n",
      "total params : 43,040,704\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm.models as models\n",
    "from timm import create_model\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))\n",
    "# print(model_names)\n",
    "x = torch.randn((16,3,600,600))\n",
    "model = create_model(\"efficientnet_b6\", pretrained=False)\n",
    "# print(model)\n",
    "# model = model.cuda()\n",
    "output = model(x)\n",
    "print(output.shape)\n",
    "print(\"total params : {:,}\".format(sum([p.data.nelement() for p in model.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000])\n",
      "total params : 25,557,032\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))\n",
    "# print(model_names)\n",
    "\n",
    "x = torch.randn((16,3,512,512))\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "output = model(x)\n",
    "print(output.shape)\n",
    "print(\"total params : {:,}\".format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "# model = models.efficientnet_b0(pretrained=True)\n",
    "# output = model(x)\n",
    "# print(output.shape)\n",
    "# print(\"total params : {:,}\".format(sum([p.data.nelement() for p in model.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3,4\"\n",
    "\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "temp = datetime.now().strftime(\"%d-%m-%y,%H:%M:%S\")\n",
    "# wandb.init(project=\"Cencer-Metastasis\", entity=\"jaejungscene\", name=temp)\n",
    "del temp\n",
    "\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "CFG = {\n",
    "    'IMG_SIZE':512,\n",
    "    'EPOCHS':5,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':16,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df['암의 장경'] = train_df['암의 장경'].fillna(train_df['암의 장경'].mean())\n",
    "train_df = train_df.fillna(0)\n",
    "\n",
    "test_df['암의 장경'] = test_df['암의 장경'].fillna(train_df['암의 장경'].mean())\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "train_df, val_df, train_labels, val_labels = train_test_split(\n",
    "                                                    train_df.drop(columns=['N_category']), \n",
    "                                                    train_df['N_category'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=CFG['SEED']\n",
    "                                                )\n",
    "\n",
    "\n",
    "def get_values(value):\n",
    "    return value.values.reshape(-1, 1)\n",
    "\n",
    "numeric_cols = ['나이', '암의 장경', 'ER_Allred_score', 'PR_Allred_score', 'KI-67_LI_percent', 'HER2_SISH_ratio']\n",
    "ignore_cols = ['ID', 'img_path', 'mask_path', '수술연월일', 'N_category']\n",
    "\n",
    "for col in train_df.columns:\n",
    "    if col in ignore_cols:\n",
    "        continue\n",
    "    if col in numeric_cols:\n",
    "        scaler = StandardScaler()\n",
    "        train_df[col] = scaler.fit_transform(get_values(train_df[col]))\n",
    "        val_df[col] = scaler.transform(get_values(val_df[col]))\n",
    "        test_df[col] = scaler.transform(get_values(test_df[col]))\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        train_df[col] = le.fit_transform(get_values(train_df[col]))\n",
    "        val_df[col] = le.transform(get_values(val_df[col]))\n",
    "        test_df[col] = le.transform(get_values(test_df[col]))\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, medical_df, labels, transforms=None, test=False):\n",
    "        self.medical_df = medical_df\n",
    "        self.transforms = transforms\n",
    "        self.labels = labels\n",
    "        self.test = test\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.test:\n",
    "            data_path = \"/home/ljj0512/private/workspace/CP_Multi-modal_Cencer-metastasis_DACON/data/test_imgs\"\n",
    "        else:\n",
    "            data_path = \"/home/ljj0512/private/workspace/CP_Multi-modal_Cencer-metastasis_DACON/data/train_imgs\"\n",
    "        img_path = os.path.join(data_path,self.medical_df[\"img_path\"].iloc[index][-14:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "                \n",
    "        if self.labels is not None:\n",
    "            tabular = torch.Tensor(self.medical_df.drop(columns=['ID', 'img_path', 'mask_path', '수술연월일']).iloc[index])\n",
    "            label = self.labels[index]\n",
    "            return image, tabular, label\n",
    "        else:\n",
    "            tabular = torch.Tensor(self.medical_df.drop(columns=['ID', 'img_path', '수술연월일']).iloc[index])\n",
    "            return image, tabular\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.medical_df)\n",
    "\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "                            A.HorizontalFlip(),\n",
    "                            A.VerticalFlip(),\n",
    "                            A.Rotate(limit=90, border_mode=cv2.BORDER_CONSTANT,p=0.3),\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_df, train_labels.values, train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "print(train_dataset[0][0].shape)\n",
    "val_dataset = CustomDataset(val_df, val_labels.values, test_transforms)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65fe116ec29312474b580f4ecbad52a94f46ea3a142b15e85ff8e68848a207e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
